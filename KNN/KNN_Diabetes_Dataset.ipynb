{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from dataset(https://www.kaggle.com/uciml/pima-indians-diabetes-database?select=diabetes.csv)\n",
    "df=pd.read_csv(\"datasets/datasets_228_482_diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing data\n",
    "X=df.iloc[:,:8]\n",
    "Y=df.iloc[:,8:]\n",
    "x_sampletrain,x_sampletest,y_sampletrain,y_sampletest=train_test_split(X,Y,test_size=0.20, random_state=42)\n",
    "#Converting the data into numpy arrays\n",
    "x_sampletrain=x_sampletrain.values\n",
    "y_sampletrain=y_sampletrain.values\n",
    "x_sampletest=x_sampletest.values\n",
    "y_sampletest=y_sampletest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate Eucledian distance\n",
    "def dist(x1,x2):\n",
    "    return np.sqrt(np.sum(x1-x2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate distance from all points and store in a dictionary\n",
    "def KNN_solve(x,y,querypoint,data,j):\n",
    "    value=[]\n",
    "    size=x.shape[0]\n",
    "    for i in range(size):\n",
    "        d=dist(x[i],querypoint)\n",
    "        value.append((d,int(y[i])))\n",
    "    data[j]=sorted(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict using data in the dictionary by choosing nearest k neighbors\n",
    "def KNN_predict(data,k=10):\n",
    "    res=[]\n",
    "    m=len(data)\n",
    "    for i in data:\n",
    "        temp=data[i]\n",
    "        temp=temp[:k]\n",
    "        temp=np.array(temp)\n",
    "        new_vals=np.unique(temp[:,1],return_counts=True)\n",
    "        index=new_vals[1].argmax()\n",
    "        pred=new_vals[0][index]\n",
    "        res.append((pred))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to calculate KNN\n",
    "def call_KNN(x_train,y_train,x_test):\n",
    "    data={}\n",
    "    size=x_test.shape[0]\n",
    "    for i in range(size):\n",
    "        KNN_solve(x_train,y_train,x_test[i],data,i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test on the  data and find the best value of K\n",
    "calc=call_KNN(x_sampletrain,y_sampletrain,x_sampletest)\n",
    "#Saving all results in a dictionary So that I dont have to calculate distance in every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.564935064935065\n",
      "2 0.6363636363636364\n",
      "3 0.6363636363636364\n",
      "4 0.6623376623376623\n",
      "5 0.6753246753246753\n",
      "6 0.6623376623376623\n",
      "7 0.6688311688311688\n",
      "8 0.6688311688311688\n",
      "9 0.6818181818181818\n",
      "10 0.6753246753246753\n",
      "11 0.6818181818181818\n",
      "12 0.6753246753246753\n",
      "13 0.7077922077922078\n",
      "14 0.6818181818181818\n",
      "15 0.6883116883116883\n",
      "16 0.6623376623376623\n",
      "17 0.6818181818181818\n",
      "18 0.6753246753246753\n",
      "19 0.6948051948051948\n",
      "20 0.6883116883116883\n",
      "21 0.6623376623376623\n",
      "22 0.6753246753246753\n",
      "23 0.6558441558441559\n",
      "24 0.6688311688311688\n",
      "25 0.6818181818181818\n",
      "26 0.6558441558441559\n",
      "27 0.6818181818181818\n",
      "28 0.6688311688311688\n",
      "29 0.6948051948051948\n",
      "30 0.6883116883116883\n",
      "31 0.7142857142857143\n",
      "32 0.7142857142857143\n",
      "33 0.7142857142857143\n",
      "34 0.7077922077922078\n",
      "35 0.7077922077922078\n",
      "36 0.7077922077922078\n",
      "37 0.7142857142857143\n",
      "38 0.7142857142857143\n",
      "39 0.7142857142857143\n",
      "40 0.7207792207792207\n",
      "41 0.7077922077922078\n",
      "42 0.7012987012987013\n",
      "43 0.7077922077922078\n",
      "44 0.7077922077922078\n",
      "45 0.7142857142857143\n",
      "46 0.7077922077922078\n",
      "47 0.7077922077922078\n",
      "48 0.7012987012987013\n",
      "49 0.7077922077922078\n",
      "50 0.6948051948051948\n",
      "51 0.7012987012987013\n",
      "52 0.6948051948051948\n",
      "53 0.7142857142857143\n",
      "54 0.7077922077922078\n",
      "55 0.7142857142857143\n",
      "56 0.7077922077922078\n",
      "57 0.7077922077922078\n",
      "58 0.7012987012987013\n",
      "59 0.7077922077922078\n",
      "60 0.7142857142857143\n",
      "61 0.7207792207792207\n",
      "62 0.7142857142857143\n",
      "63 0.7077922077922078\n",
      "64 0.7077922077922078\n",
      "65 0.7077922077922078\n",
      "66 0.7077922077922078\n",
      "67 0.7077922077922078\n",
      "68 0.7142857142857143\n",
      "69 0.7077922077922078\n",
      "70 0.7077922077922078\n",
      "71 0.7012987012987013\n",
      "72 0.7077922077922078\n",
      "73 0.7077922077922078\n",
      "74 0.7142857142857143\n",
      "75 0.7142857142857143\n",
      "76 0.7207792207792207\n",
      "77 0.7142857142857143\n",
      "78 0.7207792207792207\n",
      "79 0.7207792207792207\n",
      "80 0.7207792207792207\n",
      "81 0.7142857142857143\n",
      "82 0.7142857142857143\n",
      "83 0.7207792207792207\n",
      "84 0.7207792207792207\n",
      "85 0.7142857142857143\n",
      "86 0.7272727272727273\n",
      "87 0.7207792207792207\n",
      "88 0.7142857142857143\n",
      "89 0.7207792207792207\n",
      "90 0.7142857142857143\n",
      "91 0.7207792207792207\n",
      "92 0.7077922077922078\n",
      "93 0.7077922077922078\n",
      "94 0.7077922077922078\n",
      "95 0.7077922077922078\n",
      "96 0.7077922077922078\n",
      "97 0.7142857142857143\n",
      "98 0.7142857142857143\n",
      "99 0.7207792207792207\n",
      "100 0.7142857142857143\n",
      "101 0.7142857142857143\n",
      "102 0.7207792207792207\n",
      "103 0.7142857142857143\n",
      "104 0.7142857142857143\n",
      "105 0.7142857142857143\n",
      "106 0.7077922077922078\n",
      "107 0.7077922077922078\n",
      "108 0.7077922077922078\n",
      "109 0.7077922077922078\n",
      "110 0.7142857142857143\n",
      "111 0.7077922077922078\n",
      "112 0.7207792207792207\n",
      "113 0.7142857142857143\n",
      "114 0.7207792207792207\n",
      "115 0.7142857142857143\n",
      "116 0.7142857142857143\n",
      "117 0.7207792207792207\n",
      "118 0.7142857142857143\n",
      "119 0.7142857142857143\n",
      "120 0.7207792207792207\n",
      "121 0.7142857142857143\n",
      "122 0.7012987012987013\n",
      "123 0.7012987012987013\n",
      "124 0.6883116883116883\n",
      "125 0.6948051948051948\n",
      "126 0.7012987012987013\n",
      "127 0.7012987012987013\n",
      "128 0.7012987012987013\n",
      "129 0.7012987012987013\n",
      "130 0.7077922077922078\n",
      "131 0.7077922077922078\n",
      "132 0.7012987012987013\n",
      "133 0.7012987012987013\n",
      "134 0.7012987012987013\n",
      "135 0.7012987012987013\n",
      "136 0.6948051948051948\n",
      "137 0.6948051948051948\n",
      "138 0.6883116883116883\n",
      "139 0.6883116883116883\n",
      "140 0.6883116883116883\n",
      "141 0.6883116883116883\n",
      "142 0.6883116883116883\n",
      "143 0.6883116883116883\n",
      "144 0.6818181818181818\n",
      "145 0.6883116883116883\n",
      "146 0.6818181818181818\n",
      "147 0.6818181818181818\n",
      "148 0.6818181818181818\n",
      "149 0.6818181818181818\n"
     ]
    }
   ],
   "source": [
    "#Finding best value of K\n",
    "for k in range(1,150):\n",
    "    y_predictions=KNN_predict(calc,k)\n",
    "    print(k,accuracy_score(y_sampletest,y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions=KNN_predict(calc,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To write the output to a file\n",
    "ans=\"Outcome,\\n\"\n",
    "for i in range(len(final_prediction)):\n",
    "    ans+=str(int(final_prediction[i]))\n",
    "    ans+=\",\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"diabetes_knn.csv\",\"w\") as f:\n",
    "        f.write(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
